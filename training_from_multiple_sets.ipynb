{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_from_multiple_sets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOAM202WtxMohcwvipF5knH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gl7176/CNN_tools/blob/main/training_from_multiple_sets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl0scVF_G5VV"
      },
      "source": [
        "# Import tiles from one dataset and run a model from another dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeRHbK8bdwLy"
      },
      "source": [
        "**Before running this script, enter the drive folder links of each dataset you would like to use to train the model. Each drive folder should include (1) tiled images, (2) the `tiling_scheme.json` file, and (3) the training data associated with each tile set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRUtUEXGG5Ve"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gl7176/CNN_local/blob/main/Train_from_multiple_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "#####  <center> Be sure to update this hyperlink above if you clone and want to point to a different GitHub </center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzzjflRckvHf",
        "outputId": "04b67dcc-3a74-4e33-8fbe-afec8433b726"
      },
      "source": [
        "# set variable to the destination google drive folder you want to pull from\n",
        "drive_folder = 'https://drive.google.com/drive/folders/1DKAp-k2cHWFj9rLNhNL4i6dKoPcR3Gn6'\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('data')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "\n",
        "# this bit points the code to that google drive folder\n",
        "pointer = str(\"'\" + drive_folder.split(\"/\")[-1] + \"'\" + \" in parents\")\n",
        "\n",
        "file_list = drive.ListFile(\n",
        "    {'q': pointer}).GetList()\n",
        "\n",
        "#    this bit pulls every file in the directory specified above\n",
        "image_list = []\n",
        "count = 0\n",
        "for f in file_list:\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  if fname.endswith(\".png\"):\n",
        "    image_list.append(fname)\n",
        "    count += 1\n",
        "    if count % 10 == 0:\n",
        "      print(str(count) + \" tiles pulled\")\n",
        "  # 3. Create & download by id.\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)\n",
        "  if fname.endswith(\".h5\"):\n",
        "    inferential_model = fname\n",
        "    print(\"Pulled model: \" + fname)\n",
        "  if fname.endswith(\".csv\"):\n",
        "    if fname.endswith(\"classes.csv\"):\n",
        "      classes_file = fname\n",
        "      print(\"Pulled classes file\")\n",
        "  if fname.endswith(\".json\"):\n",
        "    if fname.endswith(\"tiling_scheme.json\"):\n",
        "      tiling_scheme_file = fname\n",
        "      print(\"Pulled tiling scheme file\")\n",
        "print(str(count) + \" tiles pulled\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pulled classes file\n",
            "Pulled tiling scheme file\n",
            "Pulled model: data/HayIsland2015_b2_e18_inference.h5\n",
            "10 tiles pulled\n",
            "20 tiles pulled\n",
            "30 tiles pulled\n",
            "40 tiles pulled\n",
            "50 tiles pulled\n",
            "60 tiles pulled\n",
            "70 tiles pulled\n",
            "80 tiles pulled\n",
            "90 tiles pulled\n",
            "100 tiles pulled\n",
            "110 tiles pulled\n",
            "120 tiles pulled\n",
            "130 tiles pulled\n",
            "134 tiles pulled\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}