{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_from_multiple_sets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNbe1N2ZW0Xo/NCNxCjFnBq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gl7176/CNN_tools/blob/main/training_from_multiple_sets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl0scVF_G5VV"
      },
      "source": [
        "# Import tiles from multiple datasets and train a model on those tiles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeRHbK8bdwLy"
      },
      "source": [
        "**Before running this script, enter the drive folder links of each dataset you would like to use to train the model. Each drive folder should include (1) tiled images, (2) the `tiling_scheme.json` file, and (3) the training data (VIA annotations) associated with each tile set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRUtUEXGG5Ve"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gl7176/CNN_tools/blob/main/training_from_multiple_sets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "#####  <center> Be sure to update this hyperlink above if you clone and want to point to a different GitHub </center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frX2c-fQ8Qkq",
        "outputId": "180799d3-9a2a-4c7c-d522-914f4a2b0cb9"
      },
      "source": [
        "# set variable to the destination google drive folder you want to pull from\n",
        "drive_folders = ['https://drive.google.com/drive/folders/1DKAp-k2cHWFj9rLNhNL4i6dKoPcR3Gn6',\n",
        "                'https://drive.google.com/drive/folders/1INuRNVKvKMy8L_Nb6lmoVbyvScWK0-0D']\n",
        "\n",
        "# manually assign IDs to the dataset, if wanted, for output labeling\n",
        "dataset_IDs = ['HI2016', 'HI2015']\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "import os, numpy as np\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "dataset_list = np.empty(len(drive_folders), dtype=object) \n",
        "for num,entry in enumerate(drive_folders):\n",
        "  print(\"new directory: dataset_{c}\".format(c=num))\n",
        "  local_download_path = os.path.expanduser(\"dataset_{c}\".format(c=num))\n",
        "  try:\n",
        "    os.makedirs(local_download_path)\n",
        "  except: pass\n",
        "  pointer = str(\"'\" + entry.split(\"/\")[-1] + \"'\" + \" in parents\")\n",
        "\n",
        "  file_list = drive.ListFile(\n",
        "      {'q': pointer}).GetList()\n",
        "\n",
        "    # 3. Create & download filetypes of interest by id.\n",
        "  count = 0\n",
        "  image_list = []\n",
        "  for f in file_list:\n",
        "    fname = os.path.join(local_download_path, f['title'])\n",
        "    if fname.endswith(\".png\"):\n",
        "      image_list.append(fname)\n",
        "      count += 1\n",
        "      if count % 10 == 0:\n",
        "        print(\"dataset_{e}: {c} tiles pulled\".format(e=num, c=count))\n",
        "      f_ = drive.CreateFile({'id': f['id']})\n",
        "      f_.GetContentFile(fname)\n",
        "    elif fname.endswith(\".csv\") or fname.endswith(\".json\"):\n",
        "      f_ = drive.CreateFile({'id': f['id']})\n",
        "      f_.GetContentFile(fname)\n",
        "  dataset_list[num] = {\"dataset_name\": local_download_path,\n",
        "                  \"annotations_file\": \"annotations_placeholder\",\n",
        "                  \"tiling_scheme_file\": \"tsf_placeholder\",\n",
        "                  \"image_list\": image_list}\n",
        "  print(\"dataset_{e}: {c} tiles pulled\".format(e=num, c=count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new directory: dataset_0\n",
            "dataset_0: 10 tiles pulled\n",
            "dataset_0: 20 tiles pulled\n",
            "dataset_0: 30 tiles pulled\n",
            "dataset_0: 40 tiles pulled\n",
            "dataset_0: 50 tiles pulled\n",
            "dataset_0: 60 tiles pulled\n",
            "dataset_0: 70 tiles pulled\n",
            "dataset_0: 80 tiles pulled\n",
            "dataset_0: 90 tiles pulled\n",
            "dataset_0: 100 tiles pulled\n",
            "dataset_0: 110 tiles pulled\n",
            "dataset_0: 120 tiles pulled\n",
            "dataset_0: 130 tiles pulled\n",
            "dataset_0: 134 tiles pulled\n",
            "new directory: dataset_1\n",
            "dataset_1: 10 tiles pulled\n",
            "dataset_1: 20 tiles pulled\n",
            "dataset_1: 30 tiles pulled\n",
            "dataset_1: 40 tiles pulled\n",
            "dataset_1: 50 tiles pulled\n",
            "dataset_1: 60 tiles pulled\n",
            "dataset_1: 70 tiles pulled\n",
            "dataset_1: 80 tiles pulled\n",
            "dataset_1: 90 tiles pulled\n",
            "dataset_1: 100 tiles pulled\n",
            "dataset_1: 110 tiles pulled\n",
            "dataset_1: 120 tiles pulled\n",
            "dataset_1: 130 tiles pulled\n",
            "dataset_1: 140 tiles pulled\n",
            "dataset_1: 150 tiles pulled\n",
            "dataset_1: 160 tiles pulled\n",
            "dataset_1: 170 tiles pulled\n",
            "dataset_1: 180 tiles pulled\n",
            "dataset_1: 190 tiles pulled\n",
            "dataset_1: 200 tiles pulled\n",
            "dataset_1: 210 tiles pulled\n",
            "dataset_1: 220 tiles pulled\n",
            "dataset_1: 230 tiles pulled\n",
            "dataset_1: 240 tiles pulled\n",
            "dataset_1: 244 tiles pulled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfrFEWZJTBva"
      },
      "source": [
        "### Identify necessary files from among files in the input directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxK-jdv2RVkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a867aba6-8663-4ddf-ca07-eed6d79171e4"
      },
      "source": [
        "import csv, json\n",
        "for num,dataset in enumerate(dataset_list):\n",
        "  for fname in os.listdir(dataset[\"dataset_name\"]):\n",
        "    if fname.endswith(\".csv\"): \n",
        "      annotations_candidate = \"{i}/{f}\".format(i=dataset[\"dataset_name\"], f=fname)\n",
        "      with open(annotations_candidate, \"r\") as f:\n",
        "        if next(csv.reader(f, delimiter=\",\"))[0:3] == ['filename', 'file_size', 'file_attributes']:\n",
        "          dataset_list[num][\"annotations_file\"] = annotations_candidate\n",
        "        else: continue\n",
        "\n",
        "    if fname.endswith(\".json\"):\n",
        "      tiling_scheme_candidate = \"{i}/{f}\".format(i=dataset[\"dataset_name\"], f=fname)\n",
        "      with open(tiling_scheme_candidate) as f:\n",
        "        try:\n",
        "          image_list = list(json.load(f)[\"tile_pointers\"][\"image_locations\"].keys())\n",
        "          dataset_list[num][\"tiling_scheme_file\"] = tiling_scheme_candidate\n",
        "        except: continue\n",
        "\n",
        "  if dataset_list[num][\"annotations_file\"] == \"annotations_placeholder\":\n",
        "    raise Exception(\"VIA annotations file not found\")\n",
        "  elif dataset_list[num][\"tiling_scheme_file\"] == \"TSF_placeholder\":\n",
        "    raise Exception(\"tiling scheme file not found\")\n",
        "\n",
        "  print(\"{d} annotations file identified as {f}\".format(d=dataset[\"dataset_name\"], f = dataset_list[num][\"annotations_file\"]))\n",
        "  print(\"{d} tiling scheme file identified as {f}\".format(d=dataset[\"dataset_name\"], f = dataset_list[num][\"tiling_scheme_file\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset_0 annotations file identified as dataset_0/via_SealCNN_TrainingData2016.csv\n",
            "dataset_0 tiling scheme file identified as dataset_0/tiling_scheme.json\n",
            "dataset_1 annotations file identified as dataset_1/via_SealCNN_TrainingData.csv\n",
            "dataset_1 tiling scheme file identified as dataset_1/tiling_scheme.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eheLKPfBl2VF"
      },
      "source": [
        "### Shuffle and split images into 2 datasets: Training & Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt_McLbfl2VF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3baf42e6-5f13-40b2-f943-6453d8e6aaf5"
      },
      "source": [
        "import random\n",
        "# set pseudo-random values for replicability\n",
        "random.seed(3)\n",
        "\n",
        "image_list = []\n",
        "for value in dataset_list:\n",
        "  image_list= image_list + value[\"image_list\"]\n",
        "\n",
        "# shuffle the image list randomly and get total count\n",
        "random.shuffle(image_list)\n",
        "total_count = len(image_list)\n",
        "\n",
        "# set indices for breaking up the total dataset into TTV parts\n",
        "valid_fraction, train_fraction = 0.2, 0.8\n",
        "\n",
        "# spit error if the math don't add up\n",
        "if (sum([valid_fraction, train_fraction]) != 1.0):\n",
        "   raise Exception(\"fractions should add up to 1\")\n",
        "\n",
        "split_index = int(total_count * train_fraction)\n",
        "\n",
        "# use indices to break up dataset into the three parts\n",
        "train_dataset, valid_dataset= image_list[:split_index], image_list[split_index:]\n",
        "print(len(valid_dataset), len(train_dataset))\n",
        "\n",
        "output_dir = \"output_directory\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# spit out CSV listing the image subsets\n",
        "subset_list = []\n",
        "for row in valid_dataset:\n",
        "        subset_list.append([row, \"validation\"])\n",
        "for row in train_dataset:\n",
        "        subset_list.append([row, \"training\"])\n",
        "with open(output_dir + '/subset_list.csv', 'w', newline='') as fp:\n",
        "    writer = csv.writer(fp)\n",
        "    writer.writerows(subset_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76 302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoMTsew-l2VF"
      },
      "source": [
        "### Reformat annotations from VIA to RetinaNet format\n",
        "The following loop pulls each annotation, line-by-line, from the VIA exported CSV, extracts the necessary information, reformats it into the format that RetinaNet requires (https://github.com/fizyr/keras-retinanet#annotations-format), then reassembles a new CSV line-by-line that RetinaNet can receive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "DQ2btGJRl2VG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6f73853-30f6-41b8-c1fe-2a8171c1f143"
      },
      "source": [
        "# Create blank list for class names\n",
        "class_list = []\n",
        "image_annotations_train, image_annotations_valid = [], []\n",
        "\n",
        "# read each line, parse it, convert it, put it all back together\n",
        "# then drop it in the appropriate subset\n",
        "for num,dataset in enumerate(dataset_list):\n",
        "  with open(dataset[\"annotations_file\"], \"r\") as f:\n",
        "      reader = csv.reader(f, delimiter=\",\")\n",
        "      for line in reader: \n",
        "          # output we want:\n",
        "          # format: path/to/image.jpg,x1,y1,x2,y2,class_name\n",
        "          # example: /data/imgs/img_001.jpg,837,346,981,456,cow\n",
        "          filename = line[0]\n",
        "          if filename == 'filename':\n",
        "              # bypassing comments in csv\n",
        "              continue\n",
        "          filename = \"{d}/{f}\".format(d=dataset[\"dataset_name\"], f=filename)\n",
        "          if '{}' in line[5]:\n",
        "              new_row = [filename,\"\",\"\",\"\",\"\",\"\"]\n",
        "              # create a blank entry for empty images\n",
        "          else:  \n",
        "            # pulling from column named \"region_shape_attributes\"\n",
        "            box_entry = json.loads(line[5])\n",
        "            top_left_x, top_left_y, width, height = box_entry[\"x\"], box_entry[\"y\"], box_entry[\"width\"], box_entry[\"height\"]\n",
        "    \n",
        "            if width == 0 or height == 0:\n",
        "                continue\n",
        "                # skip tiny/empty boxes\n",
        "            \n",
        "            # convert from \"top left and width/height\" to \"x and y values at each corner of the box\"\n",
        "            if top_left_x < 0:\n",
        "                top_left_x = 1\n",
        "            if top_left_y < 0:\n",
        "                top_left_y = 1\n",
        "            x1, x2, y1, y2 = top_left_x, top_left_x + width, top_left_y, top_left_y + height \n",
        "            \n",
        "            # pulling from column named \"region_attributes\" to get class names\n",
        "            name = json.loads(line[6])[\"Age Class\"]\n",
        "\n",
        "            # skip unknown class, in this case. Might be useful in other applications though,\n",
        "            # e.g. total object count irrespective of class\n",
        "            if name == \"Unknown\":\n",
        "                continue\n",
        "\n",
        "            # build list of classes as we encounter new names\n",
        "            if name not in class_list:\n",
        "                class_list.append(name)\n",
        "\n",
        "            # create the annotation row\n",
        "            new_row = [filename, x1, y1, x2, y2, name]\n",
        "\n",
        "          # append the row to the correct subset (training, testing, or validation)\n",
        "          if filename in train_dataset:\n",
        "              image_annotations_train.append(new_row)\n",
        "          else:\n",
        "              image_annotations_valid.append(new_row)\n",
        "\n",
        "tv_ = list(map(len, [image_annotations_train, image_annotations_valid]))\n",
        "tv = list(map(int, [x/sum(tv_)*100 for x in tv_]))\n",
        "print(\"total breakdown of annotations: {n} - {t}% training set, {v}% validation set\".format(t=str(tv[0]), v=str(tv[1]), n=tv_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total breakdown of annotations: [5760, 1408] - 80% training set, 19% validation set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHApm2aSWbuI"
      },
      "source": [
        "output_name = 'annotations_train.csv'\n",
        "for ID in dataset_IDs:\n",
        "  output_name = \"{i}_{o}\".format(i=ID, o=output_name)\n",
        "training_data_file = \"{d}/{n}\".format(d=output_dir, n=output_name)\n",
        "with open(training_data_file, 'w', newline='') as fp:\n",
        "    writer = csv.writer(fp)\n",
        "    writer.writerows(image_annotations_train)\n",
        "\n",
        "output_name = 'annotations_valid.csv'\n",
        "for ID in dataset_IDs:\n",
        "  output_name = \"{i}_{o}\".format(i=ID, o=output_name)\n",
        "validation_data_file = \"{d}/{n}\".format(d=output_dir, n=output_name)\n",
        "with open(validation_data_file, 'w', newline='') as fp:\n",
        "    writer = csv.writer(fp)\n",
        "    writer.writerows(image_annotations_valid)\n",
        "\n",
        "detection_classes = []\n",
        "for i in range(0, len(class_list)):\n",
        "    detection_classes.append([class_list[i], i])\n",
        "classes_file = \"{d}/{n}\".format(d=output_dir, n=\"classes.csv\")\n",
        "with open(classes_file, 'w', newline='') as fp:\n",
        "    writer = csv.writer(fp)\n",
        "    writer.writerows(detection_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-xdfna11L2F"
      },
      "source": [
        "### Install the Convolutional Neural Network that will do the detections. \n",
        "\n",
        "This section sets up the software and pulls code for a CNN model called \"RetinaNet\" which uses the model \"ResNet-50\" as a subcomponent. This section then loads data for an existing ResNet-50 model (pre-trained for object detection) which we will further train for our task.\n",
        "\n",
        "Disregard any errors or prompts to \"restart runtime\" unless the code stops progressing (then email me at gdl10@duke.edu)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-VXXOfd-LXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c85a1bd9-a489-41dc-ad22-3498f78063cb"
      },
      "source": [
        "# install the keras package\n",
        "! pip install keras==2.4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/19/9d8f1c86c09d05369da39b03d011cd689edef86c0e6b2777dbcedc49dfc6/Keras-2.4.0-py2.py3-none-any.whl (170kB)\n",
            "\r\u001b[K     |██                              | 10kB 22.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20kB 11.5MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 30kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 51kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 71kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 81kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 92kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 102kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 112kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 122kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 133kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 143kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 153kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 163kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.4) (2.4.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.4) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.4) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.4) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4) (3.13)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (3.12.4)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.32.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (0.2.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.15.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (0.3.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (0.36.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (0.12.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (2.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (2.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow>=2.2.0->keras==2.4) (56.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (1.28.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (3.3.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (4.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (3.10.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (3.4.1)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jb7YRXlEUUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0c3e5ee-292f-444b-95cf-a5fa9b2cf07d"
      },
      "source": [
        "# copy the files for RetinaNet\n",
        "# note that this build is now deprecated, but we are fine with that\n",
        "# now pulling from a personal clone that outputs error metrics\n",
        "! git clone https://github.com/gl7176/keras-retinanet.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-retinanet'...\n",
            "remote: Enumerating objects: 6236, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 6236 (delta 0), reused 0 (delta 0), pack-reused 6230\u001b[K\n",
            "Receiving objects: 100% (6236/6236), 13.48 MiB | 31.74 MiB/s, done.\n",
            "Resolving deltas: 100% (4218/4218), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuULO44w6yx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abd37356-736a-4927-e2d2-76a6a1c224d0"
      },
      "source": [
        "# change directory and install RetinaNet from the copied code\n",
        "% cd keras-retinanet\n",
        "\n",
        "! pip install ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-retinanet\n",
            "Processing /content/keras-retinanet\n",
            "Collecting keras-resnet==0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/76/d4/a35cbd07381139dda4db42c81b88c59254faac026109022727b45b31bcad/keras-resnet-0.2.0.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (0.29.22)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (7.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (4.1.2.30)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==1.0.0) (3.38.0)\n",
            "Requirement already satisfied: keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.4.0)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2->keras-retinanet==1.0.0) (2.5.6)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.10.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.4.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.32.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (0.36.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.3.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.4.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.12.4)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (0.3.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (0.4.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (56.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.28.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.10.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (4.2.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras>=2.2.4->keras-resnet==0.2.0->keras-retinanet==1.0.0) (0.4.8)\n",
            "Building wheels for collected packages: keras-retinanet, keras-resnet\n",
            "  Building wheel for keras-retinanet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-retinanet: filename=keras_retinanet-1.0.0-cp37-cp37m-linux_x86_64.whl size=168717 sha256=33983c3469919060fed6f56aefbbfbe490c1a8ac09c879123942da8710fda1d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/9f/57/cb0305f6f5a41fc3c11ad67b8cedfbe9127775b563337827ba\n",
            "  Building wheel for keras-resnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-resnet: filename=keras_resnet-0.2.0-py2.py3-none-any.whl size=20486 sha256=e60209384115e1ca5444b5a8c9a584f5f429c247f12192a2a087a8363b871b81\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/09/a5/497a30fd9ad9964e98a1254d1e164bcd1b8a5eda36197ecb3c\n",
            "Successfully built keras-retinanet keras-resnet\n",
            "Installing collected packages: keras-resnet, keras-retinanet\n",
            "Successfully installed keras-resnet-0.2.0 keras-retinanet-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu_IOPbC44SC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9514f114-8a1c-4969-a1fe-7402b321e68d"
      },
      "source": [
        "! python setup.py build_ext --inplace"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running build_ext\n",
            "cythoning keras_retinanet/utils/compute_overlap.pyx to keras_retinanet/utils/compute_overlap.c\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/keras-retinanet/keras_retinanet/utils/compute_overlap.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'keras_retinanet.utils.compute_overlap' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/keras_retinanet\n",
            "creating build/temp.linux-x86_64-3.7/keras_retinanet/utils\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.7m -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -c keras_retinanet/utils/compute_overlap.c -o build/temp.linux-x86_64-3.7/keras_retinanet/utils/compute_overlap.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1822:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kkeras_retinanet/utils/compute_overlap.c:610\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/keras_retinanet\n",
            "creating build/lib.linux-x86_64-3.7/keras_retinanet/utils\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/keras_retinanet/utils/compute_overlap.o -o build/lib.linux-x86_64-3.7/keras_retinanet/utils/compute_overlap.cpython-37m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.7/keras_retinanet/utils/compute_overlap.cpython-37m-x86_64-linux-gnu.so -> keras_retinanet/utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33S3M0SoI1JI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf068879-15ee-4edf-b8e0-0504e4345b59"
      },
      "source": [
        "% cd ../\n",
        "\n",
        "# get the pre-trained ResNet-50 model\n",
        "! wget -P data \"https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "--2021-04-30 19:20:19--  https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/100249425/b7184a80-9350-11e9-9cc2-454f5c616394?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210430%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210430T192020Z&X-Amz-Expires=300&X-Amz-Signature=e345ae6ad57f14ddbb7251822a30c73815096d8fa1c96c67ef2243bfe3bc5c12&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=100249425&response-content-disposition=attachment%3B%20filename%3Dresnet50_coco_best_v2.1.0.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-04-30 19:20:20--  https://github-releases.githubusercontent.com/100249425/b7184a80-9350-11e9-9cc2-454f5c616394?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210430%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210430T192020Z&X-Amz-Expires=300&X-Amz-Signature=e345ae6ad57f14ddbb7251822a30c73815096d8fa1c96c67ef2243bfe3bc5c12&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=100249425&response-content-disposition=attachment%3B%20filename%3Dresnet50_coco_best_v2.1.0.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 152662144 (146M) [application/octet-stream]\n",
            "Saving to: ‘data/resnet50_coco_best_v2.1.0.h5’\n",
            "\n",
            "resnet50_coco_best_ 100%[===================>] 145.59M  58.3MB/s    in 2.5s    \n",
            "\n",
            "2021-04-30 19:20:22 (58.3 MB/s) - ‘data/resnet50_coco_best_v2.1.0.h5’ saved [152662144/152662144]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78RVPbaTiwHB",
        "outputId": "19593563-4350-4c0d-ffac-4db6acac0e7d"
      },
      "source": [
        "import shutil\n",
        "print(os.getcwd())\n",
        "for dataset in dataset_list:\n",
        "  shutil.move(dataset[\"dataset_name\"], \"{o}/{d}\".format(o=output_dir, d=dataset[\"dataset_name\"]))\n",
        "  #original = r'original path where the directory is currently stored\\directory name'\n",
        "  #target = r'target path where the directory will be moved\\directory name'\n",
        "\n",
        "#shutil.move(original,target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_sRjr1pdJTN"
      },
      "source": [
        "image_count = 0\n",
        "for dataset in dataset_list:\n",
        "  image_count += len(dataset[\"image_list\"])\n",
        "\n",
        "import subprocess, glob\n",
        "\n",
        "epoch_number = 50\n",
        "batch_size_number = 2\n",
        "step_number = int(image_count/batch_size_number)\n",
        "print(str(step_number) + \" steps\")\n",
        "\n",
        "# terminal code for troubleshooting\n",
        "#! keras-retinanet/keras_retinanet/bin/train.py \\\n",
        "#--weights data/resnet50_coco_best_v2.1.0.h5 \\\n",
        "#--epochs 50 --steps 189 --batch-size 2 \\\n",
        "#csv output_directory/HI2015_HI2016_annotations.csv output_directory/classes.csv\n",
        "\n",
        "# this process takes a while to run, be warned!\n",
        "# you can monitor epoch outputs by output files in the \"output\" folder\n",
        "\n",
        "model_run = subprocess.check_output(['keras-retinanet/keras_retinanet/bin/train.py',\n",
        "                 '--weights', 'data/resnet50_coco_best_v2.1.0.h5',\n",
        "                 '--epochs', str(epoch_number),  '--steps', str(step_number), '--batch-size',\n",
        "                 str(batch_size_number), 'csv', training_data_file, classes_file,\n",
        "                 '--val-annotations', validation_data_file]).decode(\"utf-8\")\n",
        "print(model_run)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhz79W8kiTHx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7fd5d56-c077-4db0-b8cb-c118a8164490"
      },
      "source": [
        "list_of_files = glob.glob('snapshots/resnet*.h5')\n",
        "latest_file = max(list_of_files, key=os.path.getctime)\n",
        "epoch_final = latest_file[latest_file.index(\"_csv_\")+5:-3]\n",
        "# since the model stops running after 5 epochs of no mAP improvement, we want\n",
        "# the earliest epoch at which improvement stopped (ergo less overfit)\n",
        "best_epoch = int(epoch_final)-5\n",
        "best_model_training = latest_file.replace(\"/content/\", \"\").replace(\"_csv_\" + str(epoch_final), \"_csv_\" + str(best_epoch))\n",
        "print(best_model_training)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "snapshots/resnet50_csv_01.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apHCQjSo8WC2"
      },
      "source": [
        "This next section converts the model from training mode to inference mode so it can be used to detect our target objects (seals). Until now we've been updating the model based on its performance; now we're fixing the model in a static \"snapshot\" so we can test it out. This conversion process take a little time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YyMralKEKuz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e4a3907-660b-4f15-ff33-05ffdc44f2b3"
      },
      "source": [
        "# note that we are naming our model \"best_model_inference\" and locating it in the \"snapshots\" directory. Customize if wanted\n",
        "model_name = \"best_model_inference\"\n",
        "#! keras-retinanet/keras_retinanet/bin/convert_model.py snapshots/resnet50_csv_10.h5 snapshots/best_model_inference.h5\n",
        "subprocess.run([\"keras-retinanet/keras_retinanet/bin/convert_model.py\", best_model_training, \"snapshots/{m}.h5\".format(m=model_name)])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['keras-retinanet/keras_retinanet/bin/convert_model.py', 'snapshots/resnet50_csv_01.h5', 'snapshots/best_model_inference.h5'], returncode=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgDzXkfvcOhk"
      },
      "source": [
        "### Export model and metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW5W8tUmiYvX"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8ndsVTJcOhl"
      },
      "source": [
        "# export metrics (fast)\n",
        "files.download(\"/content/output/Epoch-{n}.png\".format(n=best_epoch))\n",
        "files.download(\"/content/output/Epoch-{n}.csv\".format(n=best_epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1lQjgH6Sy5z"
      },
      "source": [
        "#export inference model (slow)\n",
        "files.download(\"/content/{m}\".format(m=model_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8Nz2tu_xDqg"
      },
      "source": [
        "#export training model (even slower)\n",
        "files.download(\"/content/{m}\".format(m=best_model_training))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}