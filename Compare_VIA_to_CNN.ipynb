{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Points_to_VIA_annotations",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe9-qJJAav6x"
      },
      "source": [
        "#Ingest shapefiles and convert to lists of bounding boxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5jd5b4zG5Vd"
      },
      "source": [
        "**Before running this script, create a Google Drive folder with shapefiles of your VIA annotations and CNN outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRUtUEXGG5Ve"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gl7176/CNN_tools/blob/main/Compare_VIA_to_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "#####  <center> Be sure to update this hyperlink above if you clone and want to point to a different GitHub </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0SGgVrGEWZN"
      },
      "source": [
        "### Connect to our Google Drive folder and pull files\n",
        "Note: when you run this it will give you a link that you must click. You must give Google some permissions, then copy a code into a box that comes up in the output section of this code.\n",
        "\n",
        "If customizing this code, you will need to point the `drive_folder` variable to a URL for your shared google drive folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYEIuuoGpkZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc69d70e-f9c1-4376-f7dd-9cad3b22b4c3"
      },
      "source": [
        "# set variable to the destination google drive folder you want to pull from\n",
        "drive_folder = 'https://drive.google.com/drive/folders/1Nqsx27thqFaGyrBkyaLJAT4VPuhp2I3d'\n",
        "\n",
        "# enter approximate length of your object (here, a seal), in meters\n",
        "# (this variable is used to draw the box around each point)\n",
        "object_length = 2.6\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "import os, csv\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# choose a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser('data')\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "\n",
        "# this bit points the code to that google drive folder\n",
        "pointer = str(\"'\" + drive_folder.split(\"/\")[-1] + \"'\" + \" in parents\")\n",
        "\n",
        "file_list = drive.ListFile(\n",
        "    {'q': pointer}).GetList()\n",
        "\n",
        "#    this bit pulls key files from the directory specified above\n",
        "#    and checks that all necessary files are present\n",
        "\n",
        "\n",
        "for f in file_list:\n",
        "  # 3. Create & download by id.\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)\n",
        "  print(\"Pulled file: \" + fname)\n",
        "  if fname.endswith(\".shp\"):\n",
        "    ptfile = fname\n",
        "  if fname.endswith(\".json\"):\n",
        "    tiling_scheme_file = fname"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pulled file: data/VIA_test_tiles.prj\n",
            "Pulled file: data/VIA_test_tiles.cpg\n",
            "Pulled file: data/VIA_test_tiles.dbf\n",
            "Pulled file: data/VIA_test_tiles.sbn\n",
            "Pulled file: data/VIA_test_tiles.shx\n",
            "Pulled file: data/VIA_test_tiles.shp.xml\n",
            "Pulled file: data/VIA_test_tiles.sbx\n",
            "Pulled file: data/VIA_test_tiles.shp\n",
            "Pulled file: data/seal_detections.sbx\n",
            "Pulled file: data/seal_detections.sbn\n",
            "Pulled file: data/seal_detections.cpg\n",
            "Pulled file: data/seal_detections.prj\n",
            "Pulled file: data/seal_detections.shx\n",
            "Pulled file: data/seal_detections.shp\n",
            "Pulled file: data/seal_detections.dbf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK5W5lw1_tOJ",
        "outputId": "a170e713-cfb8-48c4-8962-f968f711bff2"
      },
      "source": [
        "!pip install geopandas\n",
        "!pip install affine\n",
        "!pip install rasterio"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting geopandas\n",
            "  Downloading geopandas-0.10.2-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting pyproj>=2.2.0\n",
            "  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 45.1 MB/s \n",
            "\u001b[?25hCollecting fiona>=1.8\n",
            "  Downloading Fiona-1.8.20-cp37-cp37m-manylinux1_x86_64.whl (15.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.4 MB 44.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.1.5)\n",
            "Requirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.0)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2021.10.8)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (21.2.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (1.19.5)\n",
            "Installing collected packages: munch, cligj, click-plugins, pyproj, fiona, geopandas\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.8.20 geopandas-0.10.2 munch-2.5.0 pyproj-3.2.1\n",
            "Collecting affine\n",
            "  Downloading affine-2.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: affine\n",
            "Successfully installed affine-2.3.0\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.2.10-cp37-cp37m-manylinux1_x86_64.whl (19.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.3 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.19.5)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.4.0)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.7/dist-packages (from rasterio) (2.3.0)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2021.10.8)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (21.2.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.6)\n",
            "Installing collected packages: snuggs, rasterio\n",
            "Successfully installed rasterio-1.2.10 snuggs-1.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, fiona, sys, numpy as np, geopandas\n",
        "from osgeo import ogr\n",
        "from natsort import natsorted\n",
        "\n",
        "VIA_file = \"data/VIA_test_tiles.shp\"\n",
        "CNN_file = \"data/seal_detections.shp\"\n",
        "\n",
        "def shape2box (shpfile):\n",
        "  box_list = []\n",
        "  with fiona.open(shpfile) as c:\n",
        "      shpfile_crs = c.crs\n",
        "      for i, record in enumerate(c):\n",
        "         bounding_box = []\n",
        "         shpbox = record[\"geometry\"][\"coordinates\"][0]\n",
        "         #print(record)\n",
        "         for i in reversed(shpbox[0:4]):\n",
        "             bounding_box.append(list(i))\n",
        "         entry = {\"box\":bounding_box, \"class\":record[\"properties\"][\"Detection\"]}\n",
        "         box_list.append(entry)\n",
        "  return box_list"
      ],
      "metadata": {
        "id": "Ne0VUzhwBQWn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG32SAyENlGr"
      },
      "source": [
        "### Convert shapefile to bounding box list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "boxlist1 = shape2box(VIA_file)\n",
        "boxlist2 = shape2box(CNN_file)\n",
        "\n",
        "boxes1 = [[elem['box'][2][0], elem['box'][0][0], elem['box'][2][1], elem['box'][0][1]] for elem in boxlist1 if 'box' in elem]\n",
        "boxes2 = [[elem['box'][2][0], elem['box'][0][0], elem['box'][2][1], elem['box'][0][1]] for elem in boxlist2 if 'box' in elem]\n",
        "\n",
        "detections1 = [elem['detection'] for elem in boxlist1 if 'detection' in elem]\n",
        "detections2 = [elem['detection'] for elem in boxlist2 if 'detection' in elem]\n",
        "\n",
        "bboxes1 = np.array(boxes1)\n",
        "bboxes2 = np.array(boxes2)\n",
        "\n",
        "if max(bboxes1[:, 2]) > max(bboxes2[:, 2]):\n",
        "  boxesA = bboxes1\n",
        "  boxesB = bboxes2\n",
        "  option_var = 0\n",
        "else:\n",
        "  boxesA = bboxes2\n",
        "  boxesB = bboxes1\n",
        "  option_var = 1\n",
        "\n",
        "# grab the coordinates of the bounding boxes\n",
        "\n",
        "if boxesA[0,0] > boxesA[0,1]:\n",
        "  x1_A, x2_A = boxesA[:, 1], boxesA[:, 0]\n",
        "else:\n",
        "  x1_A, x2_A = boxesA[:, 0], boxesA[:, 1]\n",
        "if boxesA[0,2] > boxesA[0,3]:\n",
        "  y1_A, y2_A = boxesA[:, 3], boxesA[:, 2]\n",
        "else:\n",
        "  y1_A, y2_A = boxesA[:, 2], boxesA[:, 3]\n",
        "\n",
        "if boxesB[0,0] > boxesB[0,1]:\n",
        "  x1_B, x2_B = boxesB[:, 1], boxesB[:, 0]\n",
        "else:\n",
        "  x1_B, x2_B = boxesB[:, 0], boxesB[:, 1]\n",
        "if boxesB[0,2] > boxesB[0,3]:\n",
        "  y1_B, y2_B = boxesB[:, 3], boxesB[:, 2]\n",
        "else:\n",
        "  y1_B, y2_B = boxesB[:, 2], boxesB[:, 3]\n",
        "\n",
        "\n",
        "\n",
        "area_A = (x2_A - x1_A + 1) * (y2_A - y1_A + 1)\n",
        "area_B = (x2_B - x1_B + 1) * (y2_B - y1_B + 1)\n",
        "idxs_A = y2_A\n",
        "idxs_B = list(range(0,len(y2_B)))\n",
        "\n",
        "# sort the indexes\n",
        "idxs_A = np.argsort(idxs_A)\n",
        "\n",
        "# initialize the list of picked indexes\n",
        "matched_A = []\n",
        "matched_B = []\n",
        "rejects_A = []\n",
        "rejects_B = []\n",
        "\n",
        "# keep looping while some indexes still remain in the indexes list\n",
        "while len(idxs_A) > 0:\n",
        "    # grab the last index in the indexes list and add the index value\n",
        "    # to the list of picked indexes\n",
        "    last = len(idxs_A) - 1\n",
        "    i = idxs_A[last]\n",
        "\n",
        "    # find the largest (x, y) coordinates for the start of the bounding\n",
        "    # box and the smallest (x, y) coordinates for the end of the bounding\n",
        "    # box\n",
        "\n",
        "    xx1 = np.maximum(x1_A[i], x1_B[idxs_B])\n",
        "    yy1 = np.maximum(y1_A[i], y1_B[idxs_B])\n",
        "    xx2 = np.minimum(x2_A[i], x2_B[idxs_B])\n",
        "    yy2 = np.minimum(y2_A[i], y2_B[idxs_B])\n",
        "\n",
        "    # compute the width and height of the bounding box\n",
        "    w, h = np.maximum(0, xx2 - xx1 + 1), np.maximum(0, yy2 - yy1 + 1)\n",
        "    \n",
        "    # compute the ratio of overlap          \n",
        "    overlap = list((w * h) / area_B[idxs_B])\n",
        "    if max(overlap) > 0.6:\n",
        "      matched_A.append(i)\n",
        "      matched_B.append(idxs_B[overlap.index(max(overlap))])\n",
        "      idxs_B = np.delete(idxs_B, overlap.index(max(overlap)))\n",
        "    else:\n",
        "      rejects_A.append(i)\n",
        "    idxs_A = np.delete(idxs_A, last)\n",
        "rejects_B = list(idxs_B)\n",
        "\n",
        "print(len(matched_A), len(matched_B), len(rejects_A), len(rejects_B))\n",
        "print(len(boxesA), len(boxesB))\n",
        "\n",
        "\n",
        "#XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX#\n",
        "# overlap is now given between each compared square and the overlap with target square.\n",
        "# must identify the compared square with max overlap beyond acceptable threshold\n",
        "# pull the indexed choice and the compared square into the matched list\n",
        "# assign if none found, where the index goes\n",
        "# when all are matched, assign where comparison remnants go\n",
        "# in any case, remove index each round to either destination to achieve loop progress \n",
        "\n",
        "# achieve all sorting by shuttling indices around\n",
        "# remember to conserve/send detection type as well by end product\n",
        "# check detection type manually, if needed, in shapefiles and GIS\n",
        "\n",
        "# return the index of the bounding boxes that were picked\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnesuxPo4jGq",
        "outputId": "d077c283-96b1-428c-89a8-e8d356650c6b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "343 343 217 93\n",
            "560 436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if option_var == 1:\n",
        "  f = geopandas.read_file(CNN_file)\n",
        "  g = geopandas.read_file(VIA_file)\n",
        "elif option_var == 0:\n",
        "  g = geopandas.read_file(CNN_file)\n",
        "  f = geopandas.read_file(VIA_file)\n",
        "\n",
        "matched_A_out = f.iloc[matched_A]\n",
        "rejects_A_out = f.iloc[rejects_A]\n",
        "matched_B_out = g.iloc[matched_B]\n",
        "rejects_B_out = g.iloc[rejects_B]\n",
        "\n",
        "# Set output directory, create it if necessary\n",
        "output_dir = 'outputs'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "matched_A_out.to_file(\"outputs/matched_A.shp\")\n",
        "rejects_A_out.to_file(\"outputs/rejects_A.shp\")\n",
        "matched_B_out.to_file(\"outputs/matched_B.shp\")\n",
        "rejects_B_out.to_file(\"outputs/rejects_B.shp\")\n"
      ],
      "metadata": {
        "id": "qgXKDANyeLKA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zip up the output directory into an archive for download\n",
        "output_file_name = 'Step_5_{o}'.format(o=output_dir)\n",
        "import subprocess\n",
        "subprocess.call(['zip', '-r', output_file_name + '.zip', '/content/' + output_dir])\n",
        "\n",
        "from google.colab import files\n",
        "files.download(output_file_name + \".zip\")"
      ],
      "metadata": {
        "id": "1F5q31C42EW8",
        "outputId": "b9ee954d-5494-4b6f-da0f-89224554ef76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7c8a14ee-a445-41f9-bdff-924ad26fdcdb\", \"Step_5_outputs.zip\", 53577)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRy7KfQSYDvf"
      },
      "source": [
        "### Output detections in VIA format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROhIQZJ5YDvf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "3c59d936-74dd-44a7-d1ab-ed4a5550079c"
      },
      "source": [
        "# add class info later, when we have it on-hand to work with\n",
        "# class_category = \"Age Class\"\n",
        "\n",
        "#2015_02_02_hay_island_flight03_s110rgb_jpeg_mosaic_group1---28.png,1613979,\"{}\",4,0,\"{\"\"name\"\":\"\"rect\"\",\"\"x\"\":615,\"\"y\"\":927,\"\"width\"\":66,\"\"height\"\":32}\",\"{\"\"Age Class\"\":\"\"Adult\"\"}\"\n",
        "#2015_02_02_hay_island_flight03_s110rgb_jpeg_mosaic_group1---28.png,1613979,\"{}\",4,1,\"{\"\"name\"\":\"\"rect\"\",\"\"x\"\":959,\"\"y\"\":917,\"\"width\"\":39,\"\"height\"\":26}\",\"{\"\"Age Class\"\":\"\"Pup\"\"}\"\n",
        "new_line = [[\"filename\",\"file_size\",\"file_attributes\",\"region_count\",\"region_id\",\"region_shape_attributes\",\"region_attributes\"]]\n",
        "\n",
        "filename = \"\"\n",
        "for detection in entry_list:\n",
        "    print(detection[\"box\"])\n",
        "    temp = []\n",
        "    if filename != detection[\"tile_ID\"]:\n",
        "      filename = detection[\"tile_ID\"]\n",
        "      count = 0\n",
        "    else:\n",
        "      count += 1\n",
        "    file_size = \"\"\n",
        "    file_attributes = \"{}\"\n",
        "    x1 = detection[\"box\"][3][0]\n",
        "    y1 = detection[\"box\"][3][1]\n",
        "    x2 = detection[\"box\"][1][0]\n",
        "    y2 = detection[\"box\"][1][1]\n",
        "    #print(\"x1={x1}, x2={x2}, y1={y1}, y2={y2}\".format(x1=x1,x2=x2,y1=y1,y2=y2))\n",
        "    region_shape_attributes = {\"name\":\"rect\", \"x\":x1, \"y\":y1, \"width\":x2-x1, \"height\":y2-y1}\n",
        "    region_count = \"\"\n",
        "    region_attributes = {}\n",
        "    region_ID = count\n",
        "    new_line.append([filename, file_size, file_attributes, region_count, region_ID, region_shape_attributes, region_attributes])\n",
        "\n",
        "for k, x in enumerate(new_line):\n",
        "  new_line[k][5],new_line[k][6] = str(x[5]).replace(\"'\",'\"'),str(x[6]).replace(\"'\",'\"')\n",
        "\n",
        "# Set output directory, create it if necessary\n",
        "output_dir = 'via_annotations'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# write out new VIA file with additional detections\n",
        "with open(output_dir + '/new_VIA_annotations.csv', 'w', newline='') as fp:\n",
        "    writer = csv.writer(fp)\n",
        "    writer.writerows(new_line)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(output_dir + '/new_VIA_annotations.csv')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-920071d97edc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdetection\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentry_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"box\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'entry_list' is not defined"
          ]
        }
      ]
    }
  ]
}